<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>About - BreastCare</title>
  <link rel="stylesheet" href="{{ url_for('static', filename='Navbar.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='About.css') }}">
</head>
<body>
  <!-- Navbar -->
  <nav class="navbar">
    <div class="navbar-logo" style="cursor:pointer;" onclick="window.location.href='/'">
      <span class="logo-icon">üéóÔ∏è</span> BreastCare
    </div>
    <ul class="navbar-links">
      <li><a href="/home">Home</a></li>
      <li><a href="/about" class="active">About</a></li>
      <li><a href="/features">Features</a></li>
      <li><a href="/upload">Upload</a></li>
      <li><a href="/contact">Contact</a></li>
    </ul>
  </nav>

  <!-- About Project -->
  <section class="about-section">
    <div class="container">
      <h1>About the Project</h1>
      <p>
        <b>BreastCare</b> is a deep learning‚Äìbased web application designed for 
        <b>early and accurate breast cancer detection</b> using <b>ultrasound images</b>.
        The system uses a <b>Segmentation-Guided U-Net++ Framework</b> to accurately 
        locate and classify breast lesions.
      </p>

      <h2>1Ô∏è‚É£ Segmentation Module</h2>
      <p>
        The segmentation stage uses <b>U-Net++</b> to identify and outline tumor regions within ultrasound scans.
        It produces a <b>binary mask</b> highlighting the exact boundaries of the tumor area.
        This helps the model focus on the most relevant regions of interest (ROIs) instead of the entire image.
      </p>
      <p>
        The segmentation model achieves a high <b>accuracy of 99.07%</b>, ensuring precise tumor boundary detection
        even in low-contrast ultrasound conditions. Techniques like skip connections, attention layers, and Dice loss
        are employed to improve performance.
      </p>

      <h2>2Ô∏è‚É£ Classification Module</h2>
      <p>
        After segmentation, the <b>CNN-based classification model</b> analyzes the localized tumor region
        to determine whether it is <b>benign</b> or <b>malignant</b>. 
        This two-stage approach mirrors how radiologists first detect a lesion and then analyze its type.
      </p>
      <p>
        The classification model achieved an overall <b>accuracy of 96.04%</b>. 
        Grad-CAM heatmaps were also used for <b>explainable AI</b>, visually confirming the model‚Äôs focus 
        on tumor areas during prediction.
      </p>
    </div>
  </section>

  <!-- Dataset Description -->
  <section class="dataset-section">
    <div class="container">
      <h2>About the Dataset (BUSI Dataset)</h2>
      <p>
        The <b>Breast Ultrasound Images (BUSI)</b> dataset was collected at 
        <b>Baheya Hospital for Early Detection and Treatment of Women‚Äôs Cancer</b> in Egypt.
        It contains <b>780 grayscale ultrasound images</b> categorized into three main types:
        <b>Normal, Benign, and Malignant.</b>
      </p>

      <table class="dataset-table">
        <thead>
          <tr>
            <th>Category</th>
            <th>Description</th>
            <th>Image Count</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td><b>Normal</b></td>
            <td>No tumor region, blank mask (healthy tissue)</td>
            <td>133</td>
          </tr>
          <tr>
            <td><b>Benign</b></td>
            <td>Non-cancerous lesion with clear boundaries and low irregularity</td>
            <td>210</td>
          </tr>
          <tr>
            <td><b>Malignant</b></td>
            <td>Cancerous lesion with irregular shape and blurred edges</td>
            <td>437</td>
          </tr>
          <tr class="total-row">
            <td><b>Total</b></td>
            <td>All categories combined</td>
            <td><b>780</b></td>
          </tr>
        </tbody>
      </table>

      <p>
        Each image was resized to <b>128√ó128 pixels</b> and normalized before training.
        Data augmentation (rotation, flipping, translation, shearing, and zooming) 
        was applied to enhance model generalization.
      </p>
    </div>
  </section>

  <!-- Dataset Categories with Images -->
  <section class="dataset-categories">
    <div class="container">

      <!-- Normal Category -->
      <div class="category-block">
        <div class="text-side">
          <h3>ü©∂ Normal Images</h3>
          <p>
            These ultrasound scans show healthy breast tissue with no tumor presence.
            Their corresponding segmentation masks are blank (all-zero), 
            helping the model learn what ‚Äúnormal‚Äù looks like.
          </p>
        </div>
        <div class="image-side">
          <img src="{{ url_for('static', filename='dataset_samples/normal1.png') }}" alt="Normal 1">
          <img src="{{ url_for('static', filename='dataset_samples/normal2.png') }}" alt="Normal 2">
          <img src="{{ url_for('static', filename='dataset_samples/normal3.png') }}" alt="Normal 3">
          <img src="{{ url_for('static', filename='dataset_samples/normal4.png') }}" alt="Normal 4">
        </div>
      </div>

      <!-- Benign Category -->
      <div class="category-block">
        <div class="text-side">
          <h3>ü©∑ Benign Tumor Images</h3>
          <p>
            Benign tumors are <b>non-cancerous</b> and usually appear with 
            smooth boundaries and consistent texture in ultrasound scans. 
            They are accompanied by binary segmentation masks marking the lesion area.
          </p>
        </div>
        <div class="image-side">
          <img src="{{ url_for('static', filename='dataset_samples/benign1.png') }}" alt="Benign 1">
          <img src="{{ url_for('static', filename='dataset_samples/benign2.png') }}" alt="Benign 2">
          <img src="{{ url_for('static', filename='dataset_samples/benign3.png') }}" alt="Benign 3">
          <img src="{{ url_for('static', filename='dataset_samples/benign4.png') }}" alt="Benign 4">
        </div>
      </div>

      <!-- Malignant Category -->
      <div class="category-block">
        <div class="text-side">
          <h3>‚ù§Ô∏è Malignant Tumor Images</h3>
          <p>
            Malignant tumors are <b>cancerous</b> and display irregular shapes, 
            blurred edges, and heterogeneous texture in scans.
            These images are critical for training the model to detect 
            life-threatening tumor patterns accurately.
          </p>
        </div>
        <div class="image-side">
          <img src="{{ url_for('static', filename='dataset_samples/malignant1.png') }}" alt="Malignant 1">
          <img src="{{ url_for('static', filename='dataset_samples/malignant2.png') }}" alt="Malignant 2">
          <img src="{{ url_for('static', filename='dataset_samples/malignant3.png') }}" alt="Malignant 3">
          <img src="{{ url_for('static', filename='dataset_samples/malignant4.png') }}" alt="Malignant 4">
        </div>
      </div>
    </div>
  </section>

  <!-- Footer -->
  <footer class="footer">
    <p>¬© 2025 BreastCare ‚Äî AI-Powered Breast Cancer Detection System | BUSI Dataset</p>
  </footer>

  <style>
    body {
      font-family: 'Poppins', sans-serif;
      background-color: #fafafa;
      margin: 0;
      padding: 0;
      color: #333;
    }

    h1, h2, h3 {
      color: #c2185b;
      text-align: center;
    }

    .about-section, .dataset-section, .dataset-categories {
      padding: 50px 10%;
      line-height: 1.8;
    }

    .dataset-table {
      width: 100%;
      border-collapse: collapse;
      margin: 30px 0;
      font-size: 1rem;
      text-align: center;
      box-shadow: 0 4px 8px rgba(0,0,0,0.05);
    }

    .dataset-table th, .dataset-table td {
      border: 1px solid #ddd;
      padding: 12px;
    }

    .dataset-table th {
      background-color: #c2185b;
      color: #fff;
    }

    .dataset-table tr:nth-child(even) {
      background-color: #f9f9f9;
    }

    .total-row {
      background-color: #ffe4ec;
      font-weight: bold;
    }

    /* Category Section */
    .category-block {
      display: flex;
      justify-content: space-between;
      align-items: center;
      flex-wrap: wrap;
      margin: 40px 0;
      background: #fff;
      padding: 20px;
      border-radius: 12px;
      box-shadow: 0 4px 10px rgba(0,0,0,0.05);
    }

    .text-side {
      flex: 1 1 40%;
      padding: 20px;
    }

    .text-side h3 {
      margin-bottom: 10px;
    }

    .image-side {
      flex: 1 1 55%;
      display: flex;
      justify-content: space-around;
      flex-wrap: wrap;
      gap: 15px;
    }

    .image-side img {
      width: 180px;
      height: 180px;
      object-fit: cover;
      border-radius: 10px;
      box-shadow: 0 4px 8px rgba(0,0,0,0.1);
      transition: transform 0.3s ease;
    }

    .image-side img:hover {
      transform: scale(1.05);
    }

    .footer {
      background-color: #222;
      color: #fff;
      text-align: center;
      padding: 15px;
      margin-top: 40px;
    }
  </style>
</body>
</html>
